{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10-fold Cross Validation for Augmented Digits Data\n",
    "> Code for training is the same as Notebook 05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from car_speech.fname_processing import load_fnames\n",
    "from car_speech.pipeline import *\n",
    "\n",
    "import string\n",
    "from random import shuffle\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_TYPE = 'digits' # 'digits' or 'letters' or 'mixed'\n",
    "LEVEL_NAME = 'IDL' # 'IDL' or '35U' or '35D' or '55U' or '55D'\n",
    "\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_strings = np.array([str(num) for num in range(0,10)])\n",
    "\n",
    "# load classified filenames\n",
    "filenames = load_fnames('noise_levels/digit_augmented_noise_levels/' + LEVEL_NAME + '.data')\n",
    "num_samples = len(filenames)\n",
    "print('number of files:', len(filenames))\n",
    "\n",
    "# shuffle\n",
    "shuffle(filenames)\n",
    "\n",
    "fold_no = 1\n",
    "acc_per_fold = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop for 10-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beg_ratio = 0\n",
    "while beg_ratio < 0.9:\n",
    "    test_beg = int(beg_ratio*num_samples)\n",
    "    test_end = int((beg_ratio+0.1)*num_samples)\n",
    "    \n",
    "    fnames_copy = deepcopy(filenames)\n",
    "    test_files = fnames_copy[test_beg:test_end]\n",
    "    del fnames_copy[test_beg:test_end]\n",
    "    \n",
    "    val_len = len(test_files)\n",
    "    val_files = fnames_copy[-val_len:]\n",
    "    del fnames_copy[-val_len:]\n",
    "    \n",
    "    train_files = fnames_copy\n",
    "    \n",
    "    beg_ratio += 0.1\n",
    "    \n",
    "    train_files = shuffle_data(train_files)\n",
    "    val_files = shuffle_data(val_files)\n",
    "    test_files = shuffle_data(test_files)\n",
    "    \n",
    "\n",
    "    # Process data using the combined pipeline\n",
    "    spectrogram_ds = preprocess_dataset(train_files, DATASET_TYPE)\n",
    "    train_ds = spectrogram_ds\n",
    "    val_ds = preprocess_dataset(val_files, DATASET_TYPE)\n",
    "    test_ds = preprocess_dataset(test_files, DATASET_TYPE)\n",
    "    print(\"Pipeline Completed\")\n",
    "    \n",
    "    # batch\n",
    "    batch_size = 64\n",
    "    train_ds = train_ds.batch(batch_size)\n",
    "    val_ds = val_ds.batch(batch_size)\n",
    "    \n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "    train_ds = train_ds.cache().prefetch(AUTOTUNE)\n",
    "    val_ds = val_ds.cache().prefetch(AUTOTUNE)\n",
    "    \n",
    "    # model\n",
    "    for spectrogram, _ in spectrogram_ds.take(1):\n",
    "        input_shape = spectrogram.shape\n",
    "#     print('Input shape:', input_shape)\n",
    "    num_labels = len(label_strings)\n",
    "\n",
    "    norm_layer = preprocessing.Normalization()\n",
    "    norm_layer.adapt(spectrogram_ds.map(lambda x, _: x))\n",
    "\n",
    "#     model = models.Sequential([\n",
    "#         layers.Input(shape=input_shape),\n",
    "#         preprocessing.Resizing(32, 32), \n",
    "#         norm_layer,\n",
    "#         layers.Conv2D(32, 3, activation='relu'),\n",
    "#         layers.Conv2D(64, 3, activation='relu'),\n",
    "#         layers.MaxPooling2D(),\n",
    "#         layers.Dropout(0.25),\n",
    "#         layers.Flatten(),\n",
    "#         layers.Dense(128, activation='relu'),\n",
    "#         layers.Dropout(0.5),\n",
    "#         layers.Dense(num_labels),\n",
    "#     ])\n",
    "\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        preprocessing.Resizing(32, 32), \n",
    "        norm_layer,\n",
    "        layers.Conv2D(128, 3, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Conv2D(128, 3, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Conv2D(128, 3, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_labels),\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    history = model.fit(\n",
    "        train_ds, \n",
    "        validation_data=val_ds,  \n",
    "        epochs=EPOCHS,\n",
    "        callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=3),\n",
    "    )\n",
    "    \n",
    "    # Test\n",
    "    test_audio = []\n",
    "    test_labels = []\n",
    "\n",
    "    for audio, label in test_ds:\n",
    "        test_audio.append(audio.numpy())\n",
    "        test_labels.append(label.numpy())\n",
    "\n",
    "    test_audio = np.array(test_audio)\n",
    "    test_labels = np.array(test_labels)\n",
    "    \n",
    "    y_pred = np.argmax(model.predict(test_audio), axis=1)\n",
    "    y_true = test_labels\n",
    "\n",
    "    test_acc = sum(y_pred == y_true) / len(y_true)\n",
    "    print(f'Fold {fold_no} - Test set accuracy: {test_acc:.0%}')\n",
    "    acc_per_fold.append(round(test_acc, 2))\n",
    "    fold_no += 1\n",
    "\n",
    "print(acc_per_fold)\n",
    "print('mean score:', round(np.mean(acc_per_fold), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done\")\n",
    "print(acc_per_fold)\n",
    "print('mean score:', round(np.mean(acc_per_fold), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
