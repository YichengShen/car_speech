{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#default_exp pipeline\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "> Steps in feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from car_speech.fname_processing import load_fnames\n",
    "\n",
    "import pathlib\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def shuffle_data(filenames):\n",
    "    return tf.random.shuffle(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Validation/Test Split \n",
    "using 80:10:10 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def train_test_split(filenames):\n",
    "    TRAIN_PORTION = 0.8\n",
    "    VAL_PORTION = 0.1\n",
    "    TEST_PORTION = 0.1\n",
    "    \n",
    "    num_samples = len(filenames)\n",
    "\n",
    "    train_end = int(num_samples*TRAIN_PORTION)\n",
    "    val_end = train_end + int(num_samples*VAL_PORTION)\n",
    "\n",
    "    train_files = filenames[:train_end]\n",
    "    val_files = filenames[train_end: val_end]\n",
    "    test_files = filenames[val_end:]\n",
    "\n",
    "    print('Training set size:', len(train_files))\n",
    "    print('Validation set size:', len(val_files))\n",
    "    print('Test set size:', len(test_files))\n",
    "    \n",
    "    return [train_files, val_files, test_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def decode_audio(audio_binary):\n",
    "    # audio --> tensor\n",
    "    audio, _ = tf.audio.decode_wav(audio_binary)\n",
    "    return tf.squeeze(audio, axis=-1)\n",
    "\n",
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # be careful with data type here\n",
    "    # this function must return a tensor\n",
    "    label_tensor = tf.strings.substr(parts[-1], pos=9, len=1)\n",
    "    return label_tensor\n",
    "\n",
    "def get_waveform_and_label(file_path):\n",
    "    label = get_label(file_path)\n",
    "    audio_binary = tf.io.read_file(file_path)\n",
    "    waveform = decode_audio(audio_binary)\n",
    "    return waveform, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def get_spectrogram(waveform):\n",
    "    diff = [16000] - tf.shape(waveform)\n",
    "    \n",
    "    waveform = tf.cast(waveform, tf.float32)\n",
    "    \n",
    "    if diff >= 0:\n",
    "        # Padding for files with less than 16000 samples\n",
    "        zero_padding = tf.zeros([16000] - tf.shape(waveform), dtype=tf.float32)\n",
    "        # Concatenate audio with padding so that all audio clips will be of the same length\n",
    "        equal_length = tf.concat([waveform, zero_padding], 0)\n",
    "    else:\n",
    "        # Cut the tail if audio > 1 second\n",
    "        equal_length = tf.slice(waveform, [0], [16000])\n",
    "        \n",
    "    spectrogram = tf.signal.stft(\n",
    "      equal_length, frame_length=255, frame_step=128)\n",
    "\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "\n",
    "    return spectrogram\n",
    "\n",
    "def get_spectrogram_and_label_id_digits(audio, label):\n",
    "    spectrogram = get_spectrogram(audio)\n",
    "    spectrogram = tf.expand_dims(spectrogram, -1)\n",
    "    label_strings = np.array([str(num) for num in range(0,10)])\n",
    "    label_id = tf.argmax(int(label == label_strings))\n",
    "    return spectrogram, label_id\n",
    "\n",
    "def get_spectrogram_and_label_id_letters(audio, label):\n",
    "    spectrogram = get_spectrogram(audio)\n",
    "    spectrogram = tf.expand_dims(spectrogram, -1)\n",
    "    label_strings = np.array(list(string.ascii_uppercase))\n",
    "    label_id = tf.argmax(int(label == label_strings))\n",
    "    return spectrogram, label_id\n",
    "\n",
    "def get_spectrogram_and_label_id_mixed(audio, label):\n",
    "    spectrogram = get_spectrogram(audio)\n",
    "    spectrogram = tf.expand_dims(spectrogram, -1)\n",
    "    label_strings = np.array([str(num) for num in range(0,10)] + list(string.ascii_uppercase))\n",
    "    label_id = tf.argmax(int(label == label_strings))\n",
    "    return spectrogram, label_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def preprocess_dataset(files, dataset_type):\n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "    files_ds = tf.data.Dataset.from_tensor_slices(files)\n",
    "    waveform_ds = files_ds.map(get_waveform_and_label, num_parallel_calls=AUTOTUNE)\n",
    "    if dataset_type == 'digits':\n",
    "        spectrogram_ds = waveform_ds.map(\n",
    "          get_spectrogram_and_label_id_digits, num_parallel_calls=AUTOTUNE)\n",
    "    elif dataset_type == 'letters':\n",
    "        spectrogram_ds = waveform_ds.map(\n",
    "          get_spectrogram_and_label_id_letters, num_parallel_calls=AUTOTUNE)\n",
    "    elif dataset_type == 'mixed':\n",
    "        spectrogram_ds = waveform_ds.map(\n",
    "          get_spectrogram_and_label_id_mixed, num_parallel_calls=AUTOTUNE)\n",
    "    return spectrogram_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of using the pipeline on digits data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of files: 1590\n",
      "Training set size: 1272\n",
      "Validation set size: 159\n",
      "Test set size: 159\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "# have to set type first\n",
    "DATASET_TYPE = 'digits'\n",
    "\n",
    "# load classified filenames\n",
    "filenames = load_fnames('noise_levels/digit_noise_levels/35U.data')\n",
    "print('number of files:', len(filenames))\n",
    "\n",
    "# shuffle\n",
    "filenames = shuffle_data(filenames)\n",
    "\n",
    "# Train/Validation/Test Split\n",
    "split_result = train_test_split(filenames)\n",
    "train_files = split_result[0]\n",
    "val_files = split_result[1]\n",
    "test_files = split_result[2]\n",
    "\n",
    "# Process data using the combined pipeline\n",
    "train_ds = preprocess_dataset(train_files, DATASET_TYPE)\n",
    "val_ds = preprocess_dataset(val_files, DATASET_TYPE)\n",
    "test_ds = preprocess_dataset(test_files, DATASET_TYPE)\n",
    "\n",
    "print(\"Completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
